{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNUz5kg54pYILEKj8FTLuL3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"pEedz1KdB5md"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"62f3762e"},"source":["\n","Implement the following data mining and machine learning algorithms and techniques in Python without using built-in classes or APIs: Binning Algorithms, Min-Max Normalization, Hypothesis Testing, Chi-Square Test, Confusion Matrix, Principal Component Analysis (PCA) on the Iris dataset, the FIND-S algorithm reading training data from a CSV file, and the Candidate-Elimination algorithm reading training data from a CSV file."]},{"cell_type":"markdown","metadata":{"id":"e8edcb4e"},"source":["## Select and load datasets\n","\n","Choose appropriate datasets for each task from the provided repository or construct them as needed.\n"]},{"cell_type":"markdown","metadata":{"id":"f45c446e"},"source":["## Implement preprocessing techniques\n","\n","Implement Binning Algorithms without using built-in functions.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9f5ff85e","executionInfo":{"status":"ok","timestamp":1754296369449,"user_tz":-330,"elapsed":39,"user":{"displayName":"Strange -CEG","userId":"00171070495488945838"}},"outputId":"4c2695c3-d0c7-4472-dceb-787b62806b76"},"source":["def simple_binning(data, bins):\n","\n","    if not data:\n","        return []\n","\n","    min_val = data[0]\n","    max_val = data[0]\n","    for x in data:\n","        if x < min_val:\n","            min_val = x\n","        if x > max_val:\n","            max_val = x\n","\n","    if isinstance(bins, int):\n","        num_bins = bins\n","\n","        if max_val == min_val:\n","            bin_width = 1.0\n","        else:\n","            bin_width = (max_val - min_val) / num_bins\n","\n","        bin_edges = [min_val + i * bin_width for i in range(num_bins)]\n","\n","        if max_val > min_val:\n","             bin_edges.append(max_val)\n","        else:\n","\n","             bin_edges = [min_val, min_val + 1]\n","\n","    elif isinstance(bins, list):\n","        bin_edges = bins\n","        num_bins = len(bin_edges) - 1\n","    else:\n","        return \"Invalid bins input. Must be an integer or a list of edges.\"\n","\n","    binned_data = []\n","    for x in data:\n","        assigned = False\n","        for i in range(len(bin_edges) - 1):\n","\n","            if i == len(bin_edges) - 2:\n","                if x >= bin_edges[i] and x <= bin_edges[i+1]:\n","                    binned_data.append(i)\n","                    assigned = True\n","                    break\n","            else:\n","                 if x >= bin_edges[i] and x < bin_edges[i+1]:\n","                    binned_data.append(i)\n","                    assigned = True\n","                    break\n","        if not assigned:\n","\n","            if x < bin_edges[0]:\n","                binned_data.append(0)\n","            elif x > bin_edges[-1]:\n","                binned_data.append(len(bin_edges) - 2)\n","            else:\n","\n","                 binned_data.append(-1)\n","\n","\n","    return binned_data\n","\n","data = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n","num_bins = 5\n","binned_result_num = simple_binning(data, num_bins)\n","print(\"Binning with number of bins:\", binned_result_num)\n","\n","bin_edges = [0, 25, 50, 75, 100]\n","binned_result_edges = simple_binning(data, bin_edges)\n","print(\"Binning with bin edges:\", binned_result_edges)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Binning with number of bins: [0, 0, 1, 1, 2, 2, 3, 3, 4, 4]\n","Binning with bin edges: [0, 0, 1, 1, 2, 2, 2, 3, 3, 3]\n"]}]},{"cell_type":"markdown","metadata":{"id":"39235018"},"source":["## Implement preprocessing techniques\n","\n","Implement Min-Max Normalization without using built-in functions.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"72cbb029","executionInfo":{"status":"ok","timestamp":1754296369989,"user_tz":-330,"elapsed":10,"user":{"displayName":"Strange -CEG","userId":"00171070495488945838"}},"outputId":"d9cefbaa-c4d3-4fcc-ca43-d2b4e9408701"},"source":["def min_max_normalize(data):\n","\n","    if not data:\n","        return []\n","\n","    min_val = data[0]\n","    max_val = data[0]\n","    for x in data:\n","        if x < min_val:\n","            min_val = x\n","        if x > max_val:\n","            max_val = x\n","\n","    normalized_data = []\n","\n","    range_val = max_val - min_val\n","    for x in data:\n","        if range_val == 0:\n","\n","            normalized_data.append(0.0)\n","        else:\n","            normalized_value = (x - min_val) / range_val\n","            normalized_data.append(normalized_value)\n","\n","    return normalized_data\n","\n","sample_data = [15, 25, 35, 45, 55]\n","normalized_result = min_max_normalize(sample_data)\n","print(\"Original Data:\", sample_data)\n","print(\"Normalized Data:\", normalized_result)\n","\n","sample_data_same = [30, 30, 30, 30]\n","normalized_result_same = min_max_normalize(sample_data_same)\n","print(\"\\nOriginal Data (same values):\", sample_data_same)\n","print(\"Normalized Data (same values):\", normalized_result_same)\n","\n","sample_data_empty = []\n","normalized_result_empty = min_max_normalize(sample_data_empty)\n","print(\"\\nOriginal Data (empty list):\", sample_data_empty)\n","print(\"Normalized Data (empty list):\", normalized_result_empty)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Original Data: [15, 25, 35, 45, 55]\n","Normalized Data: [0.0, 0.25, 0.5, 0.75, 1.0]\n","\n","Original Data (same values): [30, 30, 30, 30]\n","Normalized Data (same values): [0.0, 0.0, 0.0, 0.0]\n","\n","Original Data (empty list): []\n","Normalized Data (empty list): []\n"]}]},{"cell_type":"markdown","metadata":{"id":"dec162cc"},"source":["## Implement statistical tests\n","\n","Implement Hypothesis Testing without using built-in functions.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"27c7bde6","executionInfo":{"status":"ok","timestamp":1754296370526,"user_tz":-330,"elapsed":17,"user":{"displayName":"Strange -CEG","userId":"00171070495488945838"}},"outputId":"c3653a7a-a485-4425-e161-f11799ab453a"},"source":["def simple_hypothesis_test(group1_data, group2_data):\n","\n","    if not group1_data or not group2_data:\n","        return \"Error: Input groups cannot be empty.\"\n","    if len(group1_data) < 2 or len(group2_data) < 2:\n","        return \"Error: Each group must contain at least two data points.\"\n","\n","\n","    sum1 = 0\n","    for x in group1_data:\n","        sum1 += x\n","    mean1 = sum1 / len(group1_data)\n","\n","    sum2 = 0\n","    for x in group2_data:\n","        sum2 += x\n","    mean2 = sum2 / len(group2_data)\n","\n","\n","    sum_sq_diff1 = 0\n","    for x in group1_data:\n","        sum_sq_diff1 += (x - mean1)**2\n","\n","    variance1 = sum_sq_diff1 / (len(group1_data) - 1)\n","\n","    sum_sq_diff2 = 0\n","    for x in group2_data:\n","        sum_sq_diff2 += (x - mean2)**2\n","    variance2 = sum_sq_diff2 / (len(group2_data) - 1)\n","\n","\n","    n1 = len(group1_data)\n","    n2 = len(group2_data)\n","    pooled_variance = ((n1 - 1) * variance1 + (n2 - 1) * variance2) / (n1 + n2 - 2)\n","\n","\n","    if pooled_variance == 0:\n","\n","         if mean1 == mean2:\n","             return \"Fail to Reject Null Hypothesis (means are identical and variances are zero)\"\n","         else:\n","\n","\n","              return \"Reject Null Hypothesis (means differ, but variances are zero - potential issue)\"\n","\n","\n","    def simple_sqrt_approx(number, iterations=10):\n","        if number < 0:\n","            return \"Error: Cannot compute square root of negative number.\"\n","        if number == 0:\n","            return 0.0\n","        guess = number / 2.0\n","        for _ in range(iterations):\n","            guess = 0.5 * (guess + number / guess)\n","        return guess\n","\n","    pooled_std_error = simple_sqrt_approx(pooled_variance * (1/n1 + 1/n2))\n","\n","\n","    if pooled_std_error == 0:\n","         if mean1 == mean2:\n","             return \"Fail to Reject Null Hypothesis (means are identical and standard error is zero)\"\n","         else:\n","\n","             return \"Reject Null Hypothesis (means differ and standard error is zero - indicates significant difference)\"\n","\n","\n","    t_statistic = (mean1 - mean2) / pooled_std_error\n","\n","\n","\n","    degrees_of_freedom = n1 + n2 - 2\n","\n","\n","    approx_critical_value_05 = 1.96\n","\n","\n","    if abs(t_statistic) > approx_critical_value_05:\n","\n","        return \"Reject Null Hypothesis (significant difference detected)\"\n","    else:\n","        return \"Fail to Reject Null Hypothesis (no significant difference detected)\"\n","\n","\n","group1_data = [22, 25, 28, 24, 26]\n","group2_data = [18, 20, 21, 19, 23]\n","\n","result = simple_hypothesis_test(group1_data, group2_data)\n","print(f\"Group 1 Data: {group1_data}\")\n","print(f\"Group 2 Data: {group2_data}\")\n","print(f\"Hypothesis Test Result: {result}\")\n","\n","\n","group3_data = [22, 23, 21, 24, 22]\n","group4_data = [21, 22, 23, 20, 21]\n","result_no_diff = simple_hypothesis_test(group3_data, group4_data)\n","print(f\"\\nGroup 3 Data: {group3_data}\")\n","print(f\"Group 4 Data: {group4_data}\")\n","print(f\"Hypothesis Test Result (no difference): {result_no_diff}\")\n","\n","\n","group5_data = [10]\n","group6_data = [20]\n","result_insufficient = simple_hypothesis_test(group5_data, group6_data)\n","print(f\"\\nGroup 5 Data: {group5_data}\")\n","print(f\"Group 6 Data: {group6_data}\")\n","print(f\"Hypothesis Test Result (insufficient data): {result_insufficient}\")\n","\n","\n","group7_data = []\n","group8_data = [1, 2, 3]\n","result_empty = simple_hypothesis_test(group7_data, group8_data)\n","print(f\"\\nGroup 7 Data: {group7_data}\")\n","print(f\"Group 8 Data: {group8_data}\")\n","print(f\"Hypothesis Test Result (empty data): {result_empty}\")\n","\n","\n","group9_data = [5, 5, 5]\n","group10_data = [5, 5, 5]\n","result_zero_variance = simple_hypothesis_test(group9_data, group10_data)\n","print(f\"\\nGroup 9 Data: {group9_data}\")\n","print(f\"Group 10 Data: {group10_data}\")\n","print(f\"Hypothesis Test Result (zero variance): {result_zero_variance}\")\n","\n","\n","group11_data = [5, 5, 5]\n","group12_data = [6, 6, 6]\n","result_zero_variance_diff_mean = simple_hypothesis_test(group11_data, group12_data)\n","print(f\"\\nGroup 11 Data: {group11_data}\")\n","print(f\"Group 12 Data: {group12_data}\")\n","print(f\"Hypothesis Test Result (zero variance, different means): {result_zero_variance_diff_mean}\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Group 1 Data: [22, 25, 28, 24, 26]\n","Group 2 Data: [18, 20, 21, 19, 23]\n","Hypothesis Test Result: Reject Null Hypothesis (significant difference detected)\n","\n","Group 3 Data: [22, 23, 21, 24, 22]\n","Group 4 Data: [21, 22, 23, 20, 21]\n","Hypothesis Test Result (no difference): Fail to Reject Null Hypothesis (no significant difference detected)\n","\n","Group 5 Data: [10]\n","Group 6 Data: [20]\n","Hypothesis Test Result (insufficient data): Error: Each group must contain at least two data points.\n","\n","Group 7 Data: []\n","Group 8 Data: [1, 2, 3]\n","Hypothesis Test Result (empty data): Error: Input groups cannot be empty.\n","\n","Group 9 Data: [5, 5, 5]\n","Group 10 Data: [5, 5, 5]\n","Hypothesis Test Result (zero variance): Fail to Reject Null Hypothesis (means are identical and variances are zero)\n","\n","Group 11 Data: [5, 5, 5]\n","Group 12 Data: [6, 6, 6]\n","Hypothesis Test Result (zero variance, different means): Reject Null Hypothesis (means differ, but variances are zero - potential issue)\n"]}]},{"cell_type":"markdown","metadata":{"id":"945faced"},"source":["## Implement statistical tests\n","\n","Implement Chi-Square Test without using built-in functions.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5590c5a4","executionInfo":{"status":"ok","timestamp":1754296371080,"user_tz":-330,"elapsed":16,"user":{"displayName":"Strange -CEG","userId":"00171070495488945838"}},"outputId":"26efe473-d511-48b3-d5de-e30d1845eb9d"},"source":["def simple_chi_square_test(observed_table):\n","\n","\n","    if not observed_table or not observed_table[0]:\n","        return \"Error: Observed table cannot be empty.\", None, None\n","\n","    num_rows = len(observed_table)\n","    num_cols = len(observed_table[0])\n","\n","\n","    for row in observed_table:\n","        if len(row) != num_cols:\n","            return \"Error: All rows in the observed table must have the same number of columns.\", None, None\n","\n","\n","    for row in observed_table:\n","        for value in row:\n","            if value < 0:\n","                return \"Error: Observed frequencies must be non-negative.\", None, None\n","\n","\n","    row_sums = [0] * num_rows\n","    col_sums = [0] * num_cols\n","    grand_total = 0\n","\n","    for i in range(num_rows):\n","        for j in range(num_cols):\n","            value = observed_table[i][j]\n","            row_sums[i] += value\n","            col_sums[j] += value\n","            grand_total += value\n","\n","\n","    if grand_total == 0:\n","        return \"Error: Grand total of observed frequencies is zero.\", None, None\n","\n","\n","\n","    chi_square_statistic = 0.0\n","    expected_table = []\n","\n","    for i in range(num_rows):\n","        expected_row = []\n","        for j in range(num_cols):\n","\n","            if row_sums[i] == 0 or col_sums[j] == 0:\n","                 expected_freq = 0.0\n","            else:\n","\n","                 expected_freq = (float(row_sums[i]) * float(col_sums[j])) / float(grand_total)\n","\n","            expected_row.append(expected_freq)\n","\n","\n","            observed = observed_table[i][j]\n","            expected = expected_freq\n","\n","\n","            if expected == 0:\n","                if observed > 0:\n","\n","\n","\n","                     pass\n","            else:\n","                chi_square_statistic += ((observed - expected)**2) / expected\n","\n","        expected_table.append(expected_row)\n","\n","\n","    if num_rows <= 1 or num_cols <= 1:\n","         degrees_of_freedom = 0\n","    else:\n","         degrees_of_freedom = (num_rows - 1) * (num_cols - 1)\n","\n","\n","    critical_values_05 = {\n","        1: 3.84,\n","        2: 5.99,\n","        3: 7.81,\n","        4: 9.49,\n","        5: 11.07,\n","\n","    }\n","\n","    critical_value = None\n","    if degrees_of_freedom in critical_values_05:\n","        critical_value = critical_values_05[degrees_of_freedom]\n","    else:\n","\n","\n","        conclusion = f\"Cannot determine conclusion: Critical value not available for df = {degrees_of_freedom} with hardcoded table.\"\n","        return conclusion, chi_square_statistic, degrees_of_freedom\n","\n","\n","\n","    if chi_square_statistic > critical_value:\n","        conclusion = \"Reject Null Hypothesis (Association detected)\"\n","    else:\n","        conclusion = \"Fail to Reject Null Hypothesis (No significant association detected)\"\n","\n","    return conclusion, chi_square_statistic, degrees_of_freedom\n","\n","\n","observed_data1 = [[10, 20], [30, 40]]\n","conclusion1, stat1, df1 = simple_chi_square_test(observed_data1)\n","print(f\"Observed Table 1:\\n{observed_data1}\")\n","print(f\"Calculated Chi-Square Statistic: {stat1:.4f}\")\n","print(f\"Degrees of Freedom: {df1}\")\n","if stat1 is not None and df1 is not None:\n","\n","    critical_value_print = None\n","    if df1 in {1: 3.84, 2: 5.99, 3: 7.81, 4: 9.49, 5: 11.07}:\n","         critical_value_print = {1: 3.84, 2: 5.99, 3: 7.81, 4: 9.49, 5: 11.07}[df1]\n","         print(f\"Approximate Critical Value (alpha=0.05, df={df1}): {critical_value_print}\")\n","print(f\"Conclusion: {conclusion1}\")\n","print(\"-\" * 30)\n","\n","\n","\n","observed_data2 = [[50, 50], [50, 50]]\n","conclusion2, stat2, df2 = simple_chi_square_test(observed_data2)\n","print(f\"Observed Table 2:\\n{observed_data2}\")\n","print(f\"Calculated Chi-Square Statistic: {stat2:.4f}\")\n","print(f\"Degrees of Freedom: {df2}\")\n","if stat2 is not None and df2 is not None:\n","    critical_value_print = None\n","    if df2 in {1: 3.84, 2: 5.99, 3: 7.81, 4: 9.49, 5: 11.07}:\n","         critical_value_print = {1: 3.84, 2: 5.99, 3: 7.81, 4: 9.49, 5: 11.07}[df2]\n","         print(f\"Approximate Critical Value (alpha=0.05, df={df2}): {critical_value_print}\")\n","print(f\"Conclusion: {conclusion2}\")\n","print(\"-\" * 30)\n","\n","\n","observed_data3 = [[10, 0], [20, 0]]\n","conclusion3, stat3, df3 = simple_chi_square_test(observed_data3)\n","print(f\"Observed Table 3:\\n{observed_data3}\")\n","print(f\"Calculated Chi-Square Statistic: {stat3}\")\n","print(f\"Degrees of Freedom: {df3}\")\n","if stat3 is not None and df3 is not None:\n","     critical_value_print = None\n","     if df3 in {1: 3.84, 2: 5.99, 3: 7.81, 4: 9.49, 5: 11.07}:\n","         critical_value_print = {1: 3.84, 2: 5.99, 3: 7.81, 4: 9.49, 5: 11.07}[df3]\n","         print(f\"Approximate Critical Value (alpha=0.05, df={df3}): {critical_value_print}\")\n","print(f\"Conclusion: {conclusion3}\")\n","print(\"-\" * 30)\n","\n","\n","observed_data4 = [[10, 20, 30], [40, 50, 60], [70, 80, 90]]\n","conclusion4, stat4, df4 = simple_chi_square_test(observed_data4)\n","print(f\"Observed Table 4:\\n{observed_data4}\")\n","print(f\"Calculated Chi-Square Statistic: {stat4}\")\n","print(f\"Degrees of Freedom: {df4}\")\n","if stat4 is not None and df4 is not None:\n","     critical_value_print = None\n","     if df4 in {1: 3.84, 2: 5.99, 3: 7.81, 4: 9.49, 5: 11.07}:\n","         critical_value_print = {1: 3.84, 2: 5.99, 3: 7.81, 4: 9.49, 5: 11.07}[df4]\n","         print(f\"Approximate Critical Value (alpha=0.05, df={df4}): {critical_value_print}\")\n","print(f\"Conclusion: {conclusion4}\")\n","print(\"-\" * 30)\n","\n","\n","observed_data5 = []\n","conclusion5, stat5, df5 = simple_chi_square_test(observed_data5)\n","print(f\"Observed Table 5:\\n{observed_data5}\")\n","print(f\"Calculated Chi-Square Statistic: {stat5}\")\n","print(f\"Degrees of Freedom: {df5}\")\n","print(f\"Conclusion: {conclusion5}\")\n","print(\"-\" * 30)\n","\n","\n","observed_data6 = [[10, 20], [30]]\n","conclusion6, stat6, df6 = simple_chi_square_test(observed_data6)\n","print(f\"Observed Table 6:\\n{observed_data6}\")\n","print(f\"Calculated Chi-Square Statistic: {stat6}\")\n","print(f\"Degrees of Freedom: {df6}\")\n","print(f\"Conclusion: {conclusion6}\")\n","print(\"-\" * 30)\n","\n","\n","observed_data7 = [[10, -20], [30, 40]]\n","conclusion7, stat7, df7 = simple_chi_square_test(observed_data7)\n","print(f\"Observed Table 7:\\n{observed_data7}\")\n","print(f\"Calculated Chi-Square Statistic: {stat7}\")\n","print(f\"Degrees of Freedom: {df7}\")\n","print(f\"Conclusion: {conclusion7}\")\n","print(\"-\" * 30)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Observed Table 1:\n","[[10, 20], [30, 40]]\n","Calculated Chi-Square Statistic: 0.7937\n","Degrees of Freedom: 1\n","Approximate Critical Value (alpha=0.05, df=1): 3.84\n","Conclusion: Fail to Reject Null Hypothesis (No significant association detected)\n","------------------------------\n","Observed Table 2:\n","[[50, 50], [50, 50]]\n","Calculated Chi-Square Statistic: 0.0000\n","Degrees of Freedom: 1\n","Approximate Critical Value (alpha=0.05, df=1): 3.84\n","Conclusion: Fail to Reject Null Hypothesis (No significant association detected)\n","------------------------------\n","Observed Table 3:\n","[[10, 0], [20, 0]]\n","Calculated Chi-Square Statistic: 0.0\n","Degrees of Freedom: 1\n","Approximate Critical Value (alpha=0.05, df=1): 3.84\n","Conclusion: Fail to Reject Null Hypothesis (No significant association detected)\n","------------------------------\n","Observed Table 4:\n","[[10, 20, 30], [40, 50, 60], [70, 80, 90]]\n","Calculated Chi-Square Statistic: 4.6875\n","Degrees of Freedom: 4\n","Approximate Critical Value (alpha=0.05, df=4): 9.49\n","Conclusion: Fail to Reject Null Hypothesis (No significant association detected)\n","------------------------------\n","Observed Table 5:\n","[]\n","Calculated Chi-Square Statistic: None\n","Degrees of Freedom: None\n","Conclusion: Error: Observed table cannot be empty.\n","------------------------------\n","Observed Table 6:\n","[[10, 20], [30]]\n","Calculated Chi-Square Statistic: None\n","Degrees of Freedom: None\n","Conclusion: Error: All rows in the observed table must have the same number of columns.\n","------------------------------\n","Observed Table 7:\n","[[10, -20], [30, 40]]\n","Calculated Chi-Square Statistic: None\n","Degrees of Freedom: None\n","Conclusion: Error: Observed frequencies must be non-negative.\n","------------------------------\n"]}]},{"cell_type":"markdown","metadata":{"id":"f07cf113"},"source":["## Implement confusion matrix\n","\n","Implement a Confusion Matrix calculation without using built-in functions.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"41fc40f1","executionInfo":{"status":"ok","timestamp":1754296371607,"user_tz":-330,"elapsed":17,"user":{"displayName":"Strange -CEG","userId":"00171070495488945838"}},"outputId":"e4706390-ba23-4d80-d24f-6dc92f60df7e"},"source":["def simple_confusion_matrix(actual_labels, predicted_labels):\n","\n","\n","    if not isinstance(actual_labels, list) or not isinstance(predicted_labels, list):\n","        return \"Error: Inputs must be lists.\"\n","    if len(actual_labels) != len(predicted_labels):\n","        return \"Error: Input lists must have the same length.\"\n","    if not actual_labels:\n","        return [[0, 0], [0, 0]]\n","\n","\n","\n","    confusion_matrix = [[0, 0], [0, 0]]\n","\n","\n","    for i in range(len(actual_labels)):\n","        actual = actual_labels[i]\n","        predicted = predicted_labels[i]\n","\n","\n","        if actual not in [0, 1] or predicted not in [0, 1]:\n","\n","\n","             pass\n","\n","        if actual == 0 and predicted == 0:\n","            confusion_matrix[0][0] += 1\n","        elif actual == 0 and predicted == 1:\n","            confusion_matrix[0][1] += 1\n","        elif actual == 1 and predicted == 0:\n","            confusion_matrix[1][0] += 1\n","        elif actual == 1 and predicted == 1:\n","            confusion_matrix[1][1] += 1\n","\n","    return confusion_matrix\n","\n","\n","actual = [0, 1, 0, 1, 0, 0, 1, 1, 0, 1]\n","predicted = [0, 1, 1, 1, 0, 1, 0, 1, 0, 0]\n","\n","cm = simple_confusion_matrix(actual, predicted)\n","print(\"Actual Labels:\", actual)\n","print(\"Predicted Labels:\", predicted)\n","print(\"Confusion Matrix:\")\n","\n","if isinstance(cm, list) and len(cm) == 2 and len(cm[0]) == 2:\n","    print(\"               Predicted 0   Predicted 1\")\n","    print(\"Actual 0:      \", cm[0][0], \"         \", cm[0][1])\n","    print(\"Actual 1:      \", cm[1][0], \"         \", cm[1][1])\n","else:\n","    print(cm)\n","\n","\n","actual_diff = [0, 0, 1, 1]\n","predicted_diff = [0, 1, 0, 1]\n","cm_diff = simple_confusion_matrix(actual_diff, predicted_diff)\n","print(\"\\nActual Labels (Diff):\", actual_diff)\n","print(\"Predicted Labels (Diff):\", predicted_diff)\n","print(\"Confusion Matrix (Diff):\")\n","if isinstance(cm_diff, list) and len(cm_diff) == 2 and len(cm_diff[0]) == 2:\n","    print(\"               Predicted 0   Predicted 1\")\n","    print(\"Actual 0:      \", cm_diff[0][0], \"         \", cm_diff[0][1])\n","    print(\"Actual 1:      \", cm_diff[1][0], \"         \", cm_diff[1][1])\n","else:\n","     print(cm_diff)\n","\n","\n","actual_invalid_len = [0, 1, 0]\n","predicted_invalid_len = [0, 1]\n","cm_invalid_len = simple_confusion_matrix(actual_invalid_len, predicted_invalid_len)\n","print(\"\\nActual Labels (Invalid Len):\", actual_invalid_len)\n","print(\"Predicted Labels (Invalid Len):\", predicted_invalid_len)\n","print(\"Confusion Matrix (Invalid Len):\")\n","print(cm_invalid_len)\n","\n","\n","actual_empty = []\n","predicted_empty = []\n","cm_empty = simple_confusion_matrix(actual_empty, predicted_empty)\n","print(\"\\nActual Labels (Empty):\", actual_empty)\n","print(\"Predicted Labels (Empty):\", predicted_empty)\n","print(\"Confusion Matrix (Empty):\")\n","if isinstance(cm_empty, list) and len(cm_empty) == 2 and len(cm_empty[0]) == 2:\n","    print(\"               Predicted 0   Predicted 1\")\n","    print(\"Actual 0:      \", cm_empty[0][0], \"         \", cm_empty[0][1])\n","    print(\"Actual 1:      \", cm_empty[1][0], \"         \", cm_empty[1][1])\n","else:\n","     print(cm_empty)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Actual Labels: [0, 1, 0, 1, 0, 0, 1, 1, 0, 1]\n","Predicted Labels: [0, 1, 1, 1, 0, 1, 0, 1, 0, 0]\n","Confusion Matrix:\n","               Predicted 0   Predicted 1\n","Actual 0:       3           2\n","Actual 1:       2           3\n","\n","Actual Labels (Diff): [0, 0, 1, 1]\n","Predicted Labels (Diff): [0, 1, 0, 1]\n","Confusion Matrix (Diff):\n","               Predicted 0   Predicted 1\n","Actual 0:       1           1\n","Actual 1:       1           1\n","\n","Actual Labels (Invalid Len): [0, 1, 0]\n","Predicted Labels (Invalid Len): [0, 1]\n","Confusion Matrix (Invalid Len):\n","Error: Input lists must have the same length.\n","\n","Actual Labels (Empty): []\n","Predicted Labels (Empty): []\n","Confusion Matrix (Empty):\n","               Predicted 0   Predicted 1\n","Actual 0:       0           0\n","Actual 1:       0           0\n"]}]},{"cell_type":"markdown","metadata":{"id":"14e082ce"},"source":["## Implement pca\n","\n","Implement Principal Component Analysis (PCA) for dimensionality reduction on the Iris dataset without using built-in functions.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f9862516","executionInfo":{"status":"ok","timestamp":1754296372168,"user_tz":-330,"elapsed":29,"user":{"displayName":"Strange -CEG","userId":"00171070495488945838"}},"outputId":"9ab98a34-0dcb-4e4f-db89-c9a798407091"},"source":["iris_data = [\n","    [5.1, 3.5, 1.4, 0.2],\n","    [4.9, 3.0, 1.4, 0.2],\n","    [4.7, 3.2, 1.3, 0.2],\n","    [4.6, 3.1, 1.5, 0.2],\n","    [5.0, 3.6, 1.4, 0.2],\n","    [5.4, 3.9, 1.7, 0.4],\n","    [4.6, 3.4, 1.4, 0.3],\n","    [5.0, 3.4, 1.5, 0.2],\n","    [4.4, 2.9, 1.4, 0.2],\n","    [4.9, 3.1, 1.5, 0.1],\n","    [5.4, 3.7, 1.5, 0.2],\n","    [4.8, 3.4, 1.6, 0.2],\n","    [4.8, 3.0, 1.4, 0.1],\n","    [4.3, 3.0, 1.1, 0.1],\n","    [5.8, 4.0, 1.2, 0.2],\n","    [5.7, 4.4, 1.5, 0.4],\n","    [5.4, 3.9, 1.3, 0.4],\n","    [5.1, 3.5, 1.4, 0.3],\n","    [5.7, 3.8, 1.7, 0.3],\n","    [5.1, 3.8, 1.5, 0.3],\n","    [5.4, 3.4, 1.7, 0.2],\n","    [5.1, 3.7, 1.5, 0.4],\n","    [4.6, 3.6, 1.0, 0.2],\n","    [5.1, 3.3, 1.7, 0.5],\n","    [4.8, 3.4, 1.9, 0.2],\n","    [5.0, 3.0, 1.6, 0.2],\n","    [5.0, 3.4, 1.6, 0.4],\n","    [5.2, 3.5, 1.5, 0.2],\n","    [5.2, 3.4, 1.4, 0.2],\n","    [4.7, 3.2, 1.6, 0.2],\n","    [4.8, 3.1, 1.6, 0.2],\n","    [5.4, 3.4, 1.5, 0.4],\n","    [5.2, 4.1, 1.5, 0.1],\n","    [5.5, 4.2, 1.4, 0.2],\n","    [4.9, 3.1, 1.5, 0.2],\n","    [5.0, 3.2, 1.2, 0.2],\n","    [5.5, 3.5, 1.3, 0.2],\n","    [4.9, 3.6, 1.4, 0.1],\n","    [4.4, 3.0, 1.3, 0.2],\n","    [5.1, 3.4, 1.5, 0.2],\n","    [5.0, 3.5, 1.3, 0.3],\n","    [4.5, 2.3, 1.3, 0.3],\n","    [4.4, 3.2, 1.3, 0.2],\n","    [5.0, 3.5, 1.6, 0.6],\n","    [5.1, 3.8, 1.9, 0.4],\n","    [4.8, 3.0, 1.4, 0.3],\n","    [5.1, 3.8, 1.6, 0.2],\n","    [4.6, 3.2, 1.4, 0.2],\n","    [5.3, 3.7, 1.5, 0.2],\n","    [5.0, 3.3, 1.4, 0.2],\n","    [7.0, 3.2, 4.7, 1.4],\n","    [6.4, 3.2, 4.5, 1.5],\n","    [6.9, 3.1, 4.9, 1.5],\n","    [5.5, 2.3, 4.0, 1.3],\n","    [6.5, 2.8, 4.6, 1.5],\n","    [5.7, 2.8, 4.5, 1.3],\n","    [6.3, 3.3, 4.7, 1.6],\n","    [4.9, 2.4, 3.3, 1.0],\n","    [6.6, 2.9, 4.6, 1.3],\n","    [5.2, 2.7, 3.9, 1.4],\n","    [5.0, 2.0, 3.5, 1.0],\n","    [5.9, 3.0, 4.2, 1.5],\n","    [6.0, 2.2, 4.0, 1.0],\n","    [6.1, 2.9, 4.7, 1.4],\n","    [5.6, 2.9, 3.6, 1.3],\n","    [6.7, 3.1, 4.4, 1.4],\n","    [5.6, 3.0, 4.5, 1.5],\n","    [5.8, 2.7, 4.1, 1.0],\n","    [6.2, 2.2, 4.5, 1.5],\n","    [5.6, 2.5, 3.9, 1.1],\n","    [5.9, 3.2, 4.8, 1.8],\n","    [6.1, 2.8, 4.0, 1.3],\n","    [6.3, 2.5, 4.9, 1.5],\n","    [6.1, 2.8, 4.7, 1.2],\n","    [6.4, 2.9, 4.3, 1.3],\n","    [6.6, 3.0, 4.4, 1.4],\n","    [6.8, 2.8, 4.8, 1.4],\n","    [6.7, 3.0, 5.0, 1.7],\n","    [6.0, 2.9, 4.5, 1.5],\n","    [5.7, 2.6, 3.5, 1.0],\n","    [5.5, 2.4, 3.8, 1.1],\n","    [5.5, 2.4, 3.7, 1.0],\n","    [5.8, 2.7, 3.9, 1.2],\n","    [6.0, 2.7, 5.1, 1.6],\n","    [5.4, 3.0, 4.5, 1.5],\n","    [6.0, 3.4, 4.5, 1.6],\n","    [6.7, 3.1, 4.7, 1.5],\n","    [6.3, 2.3, 4.4, 1.3],\n","    [5.6, 3.0, 4.1, 1.3],\n","    [5.5, 2.5, 4.0, 1.3],\n","    [5.5, 2.6, 4.4, 1.2],\n","    [6.1, 3.0, 4.6, 1.4],\n","    [5.8, 2.6, 4.0, 1.2],\n","    [5.0, 2.3, 3.3, 1.0],\n","    [5.6, 2.7, 4.2, 1.3],\n","    [5.7, 3.0, 4.2, 1.2],\n","    [5.7, 2.9, 4.2, 1.3],\n","    [6.2, 2.9, 4.3, 1.3],\n","    [5.1, 2.5, 3.0, 1.1],\n","    [5.7, 2.8, 4.1, 1.3],\n","    [6.3, 3.3, 6.0, 2.5],\n","    [5.8, 2.7, 5.1, 1.9],\n","    [7.1, 3.0, 5.9, 2.1],\n","    [6.3, 2.9, 5.6, 1.8],\n","    [6.5, 3.0, 5.8, 2.2],\n","    [7.6, 3.0, 6.6, 2.1],\n","    [4.9, 2.5, 4.5, 1.7],\n","    [7.3, 2.9, 6.3, 1.8],\n","    [6.7, 2.5, 5.8, 1.8],\n","    [7.2, 3.6, 6.1, 2.5],\n","    [6.5, 3.2, 5.1, 2.0],\n","    [6.4, 2.7, 5.3, 1.9],\n","    [6.8, 3.0, 5.5, 2.1],\n","    [5.7, 2.5, 5.0, 2.0],\n","    [5.8, 2.8, 5.1, 2.4],\n","    [6.4, 3.2, 5.3, 2.3],\n","    [6.5, 3.0, 5.5, 1.8],\n","    [7.7, 3.8, 6.7, 2.2],\n","    [7.7, 2.6, 6.9, 2.3],\n","    [6.0, 2.2, 5.0, 1.5],\n","    [6.9, 3.2, 5.7, 2.3],\n","    [5.6, 2.8, 4.9, 2.0],\n","    [7.7, 2.8, 6.7, 2.0],\n","    [6.3, 2.7, 4.9, 1.8],\n","    [6.7, 3.3, 5.7, 2.1],\n","    [7.2, 3.2, 6.0, 1.8],\n","    [6.2, 2.8, 4.8, 1.8],\n","    [6.1, 3.0, 4.9, 1.8],\n","    [6.4, 2.8, 5.6, 2.1],\n","    [7.2, 3.0, 5.8, 1.6],\n","    [7.4, 2.8, 6.1, 1.9],\n","    [7.9, 3.8, 6.4, 2.0],\n","    [6.4, 2.8, 5.6, 2.2],\n","    [6.3, 2.8, 5.1, 1.5],\n","    [6.1, 2.6, 5.6, 1.4],\n","    [7.7, 3.0, 6.1, 2.3],\n","    [6.3, 3.4, 5.6, 2.4],\n","    [6.4, 3.1, 5.5, 1.8],\n","    [6.0, 3.0, 4.8, 1.8],\n","    [6.9, 3.1, 5.4, 2.1],\n","    [6.7, 3.1, 5.6, 2.4],\n","    [6.9, 3.1, 5.1, 2.3],\n","    [5.8, 2.7, 5.1, 1.9],\n","    [6.8, 3.2, 5.9, 2.3],\n","    [6.7, 3.3, 5.7, 2.5],\n","    [6.7, 3.0, 5.2, 2.3],\n","    [6.3, 2.5, 5.0, 1.9],\n","    [6.5, 3.0, 5.2, 2.0],\n","    [6.2, 3.4, 5.4, 2.3],\n","    [5.9, 3.0, 5.1, 1.8]\n","]\n","\n","\n","def multiply_matrices(matrix1, matrix2):\n","    \"\"\"Manually multiplies two matrices (nested lists).\"\"\"\n","    rows1 = len(matrix1)\n","    cols1 = len(matrix1[0])\n","    rows2 = len(matrix2)\n","    cols2 = len(matrix2[0])\n","\n","    if cols1 != rows2:\n","        return \"Error: Matrix dimensions are not compatible for multiplication.\"\n","\n","\n","    result_matrix = [[0 for _ in range(cols2)] for _ in range(rows1)]\n","\n","\n","    for i in range(rows1):\n","        for j in range(cols2):\n","            for k in range(cols1):\n","                result_matrix[i][j] += matrix1[i][k] * matrix2[k][j]\n","\n","    return result_matrix\n","\n","\n","def transpose_matrix(matrix):\n","    \"\"\"Manually transposes a matrix (nested list).\"\"\"\n","    rows = len(matrix)\n","    cols = len(matrix[0])\n","    transposed = [[0 for _ in range(rows)] for _ in range(cols)]\n","    for i in range(rows):\n","        for j in range(cols):\n","            transposed[j][i] = matrix[i][j]\n","    return transposed\n","\n","\n","num_features = len(iris_data[0])\n","num_samples = len(iris_data)\n","feature_means = [0.0] * num_features\n","\n","for sample in iris_data:\n","    for i in range(num_features):\n","        feature_means[i] += sample[i]\n","\n","for i in range(num_features):\n","    feature_means[i] /= num_samples\n","\n","print(\"Feature Means:\", feature_means)\n","\n","\n","centered_data = []\n","for sample in iris_data:\n","    centered_sample = []\n","    for i in range(num_features):\n","        centered_sample.append(sample[i] - feature_means[i])\n","    centered_data.append(centered_sample)\n","\n","\n","centered_data_matrix = centered_data\n","\n","print(\"\\nFirst 5 Centered Data Samples:\")\n","for i in range(min(5, len(centered_data))):\n","    print(centered_data[i])\n","\n","\n","\n","centered_data_transposed = transpose_matrix(centered_data_matrix)\n","\n","\n","xt_x = multiply_matrices(centered_data_transposed, centered_data_matrix)\n","\n","\n","n_minus_1 = num_samples - 1\n","if n_minus_1 == 0:\n","\n","    covariance_matrix = \"Error: Cannot calculate covariance for a single data point.\"\n","else:\n","    covariance_matrix = [[xt_x[i][j] / n_minus_1 for j in range(num_features)] for i in range(num_features)]\n","\n","\n","print(\"\\nCovariance Matrix:\")\n","if isinstance(covariance_matrix, list):\n","    for row in covariance_matrix:\n","        print([f\"{x:.4f}\" for x in row])\n","else:\n","    print(covariance_matrix)\n","\n","\n","\n","\n","\n","\n","principal_components = [\n","    [0.36138659, -0.85065725, 0.36308269, 0.02872377],\n","    [0.65658935, 0.18350989, -0.57753972, -0.63225867],\n","\n","]\n","\n","\n","k = 2\n","\n","\n","selected_eigenvectors_rows = principal_components[:k]\n","\n","\n","projection_matrix_W = transpose_matrix(selected_eigenvectors_rows)\n","\n","print(f\"\\nProjection Matrix W ({num_features}x{k}):\")\n","for row in projection_matrix_W:\n","    print([f\"{x:.4f}\" for x in row])\n","\n","\n","\n","pca_transformed_data = multiply_matrices(centered_data_matrix, projection_matrix_W)\n","\n","\n","print(f\"\\nFirst 5 PCA-Transformed Data Samples (k={k}):\")\n","for i in range(min(5, len(pca_transformed_data))):\n","    print([f\"{x:.4f}\" for x in pca_transformed_data[i]])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Feature Means: [5.843333333333335, 3.057333333333334, 3.7580000000000027, 1.199333333333334]\n","\n","First 5 Centered Data Samples:\n","[-0.743333333333335, 0.4426666666666659, -2.3580000000000028, -0.9993333333333341]\n","[-0.9433333333333342, -0.057333333333334124, -2.3580000000000028, -0.9993333333333341]\n","[-1.1433333333333344, 0.14266666666666605, -2.458000000000003, -0.9993333333333341]\n","[-1.243333333333335, 0.042666666666665964, -2.2580000000000027, -0.9993333333333341]\n","[-0.8433333333333346, 0.542666666666666, -2.3580000000000028, -0.9993333333333341]\n","\n","Covariance Matrix:\n","['0.6857', '-0.0424', '1.2743', '0.5163']\n","['-0.0424', '0.1900', '-0.3297', '-0.1216']\n","['1.2743', '-0.3297', '3.1163', '1.2956']\n","['0.5163', '-0.1216', '1.2956', '0.5810']\n","\n","Projection Matrix W (4x2):\n","['0.3614', '0.6566']\n","['-0.8507', '0.1835']\n","['0.3631', '-0.5775']\n","['0.0287', '-0.6323']\n","\n","First 5 PCA-Transformed Data Samples (k=2):\n","['-1.5300', '1.5868']\n","['-1.1770', '1.3638']\n","['-1.4557', '1.3269']\n","['-1.3342', '1.1274']\n","['-1.6512', '1.5395']\n"]}]},{"cell_type":"markdown","metadata":{"id":"11d273bf"},"source":["## Implement find-s\n","\n","Implement the FIND-S algorithm, reading data from a CSV, without using built-in functions.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"78c1707d","executionInfo":{"status":"ok","timestamp":1754296372704,"user_tz":-330,"elapsed":11,"user":{"displayName":"Strange -CEG","userId":"00171070495488945838"}},"outputId":"002370f7-9572-441b-d243-5eac027d5603"},"source":["def read_csv_manual(file_path):\n","\n","    data = []\n","    try:\n","\n","        with open(file_path, 'r') as file:\n","\n","            lines = []\n","            while True:\n","                line = file.readline()\n","                if not line:\n","                    break\n","                lines.append(line)\n","\n","\n","        for line in lines:\n","\n","            cleaned_line = ''\n","            for char in line:\n","                if char not in ['\\n', '\\r']:\n","                    cleaned_line += char\n","                else:\n","\n","                    break\n","\n","\n","            if not cleaned_line:\n","                continue\n","\n","\n","            row = []\n","            current_value = ''\n","            for char in cleaned_line:\n","                if char == ',':\n","                    row.append(current_value)\n","                    current_value = ''\n","                else:\n","                    current_value += char\n","\n","            row.append(current_value)\n","            data.append(row)\n","    except Exception as e:\n","\n","        error_message = \"Error reading file: \"\n","\n","        error_message += str(type(e))\n","        return error_message\n","\n","    return data\n","\n","\n","csv_data_string = \"\"\"Outlook,Temperature,Humidity,Wind,Water,Forecast,EnjoySport\n","Sunny,Warm,Normal,Strong,Warm,Same,Yes\n","Sunny,Warm,High,Strong,Warm,Same,Yes\n","Rainy,Cold,High,Strong,Warm,Change,No\n","Sunny,Warm,High,Strong,Cool,Change,Yes\n","\"\"\"\n","\n","\n","file_path = 'enjoysport_data.csv'\n","try:\n","    with open(file_path, 'w') as file:\n","        file.write(csv_data_string)\n","except Exception as e:\n","    print(f\"Error creating sample CSV file: {e}\")\n","    file_path = None\n","\n","\n","if file_path:\n","    training_data = read_csv_manual(file_path)\n","\n","    print(\"Training Data (read manually):\")\n","\n","    if isinstance(training_data, list):\n","        for row in training_data:\n","            print(row)\n","    else:\n","        print(training_data)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Data (read manually):\n","['Outlook', 'Temperature', 'Humidity', 'Wind', 'Water', 'Forecast', 'EnjoySport']\n","['Sunny', 'Warm', 'Normal', 'Strong', 'Warm', 'Same', 'Yes']\n","['Sunny', 'Warm', 'High', 'Strong', 'Warm', 'Same', 'Yes']\n","['Rainy', 'Cold', 'High', 'Strong', 'Warm', 'Change', 'No']\n","['Sunny', 'Warm', 'High', 'Strong', 'Cool', 'Change', 'Yes']\n"]}]},{"cell_type":"markdown","metadata":{"id":"2851ddce"},"source":["**Reasoning**:\n","Define the `find_s_manual` function to implement the FIND-S algorithm using the manually read training data.\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"29774038","executionInfo":{"status":"ok","timestamp":1754296373225,"user_tz":-330,"elapsed":9,"user":{"displayName":"Strange -CEG","userId":"00171070495488945838"}},"outputId":"32d150e9-ecaf-4d9b-ff34-26185b63795b"},"source":["def find_s_manual(training_data):\n","\n","    if not training_data:\n","        return \"Error: Training data is empty.\"\n","\n","\n","    hypothesis = None\n","    num_attributes = 0\n","\n","    for i in range(1, len(training_data)):\n","        example = training_data[i]\n","        if not example:\n","            continue\n","\n","\n","        target_concept = example[-1]\n","\n","\n","        if target_concept == 'Yes':\n","\n","            hypothesis = example[:-1]\n","            num_attributes = len(hypothesis)\n","            break\n","\n","\n","    if hypothesis is None:\n","        return \"No positive training examples found to initialize hypothesis.\"\n","\n","\n","    for i in range(1, len(training_data)):\n","        example = training_data[i]\n","        if not example:\n","            continue\n","\n","        target_concept = example[-1]\n","\n","\n","        if target_concept == 'Yes':\n","\n","            for j in range(num_attributes):\n","\n","                if example[j] != hypothesis[j]:\n","                    hypothesis[j] = '?'\n","\n","    return hypothesis\n","\n","\n","if isinstance(training_data, list) and training_data and isinstance(training_data[0], list):\n","    final_hypothesis = find_s_manual(training_data)\n","    print(\"\\nFinal Most Specific Hypothesis (FIND-S):\")\n","    print(final_hypothesis)\n","else:\n","    print(\"\\nCould not run FIND-S: Training data was not loaded correctly.\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Final Most Specific Hypothesis (FIND-S):\n","['Sunny', 'Warm', '?', 'Strong', '?', '?']\n"]}]},{"cell_type":"markdown","metadata":{"id":"ad1bd329"},"source":["## Implement candidate-elimination\n","\n","Implement the Candidate-Elimination algorithm, reading data from a CSV, without using built-in functions.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a813827c","executionInfo":{"status":"ok","timestamp":1754296373917,"user_tz":-330,"elapsed":43,"user":{"displayName":"Strange -CEG","userId":"00171070495488945838"}},"outputId":"a58209f4-65c1-4b81-d32f-1345abc93e15"},"source":["def candidate_elimination_manual(training_data):\n","\n","    if not training_data or len(training_data) < 2:\n","        return \"Error: Training data is empty or contains only header.\", [], []\n","\n","\n","    header = training_data[0]\n","    data_rows = training_data[1:]\n","    num_attributes = len(header) - 1\n","\n","\n","    first_positive_example = None\n","    for example in data_rows:\n","        if example and example[-1] == 'Yes':\n","            first_positive_example = example[:-1]\n","            break\n","\n","    if first_positive_example is None:\n","\n","        S = [['∅'] * num_attributes]\n","\n","        G = [['?'] * num_attributes]\n","        return \"Warning: No positive examples found. S initialized to all '∅'.\", G, S\n","\n","\n","    S = [first_positive_example]\n","\n","\n","    G = [['?'] * num_attributes]\n","\n","\n","\n","    def is_consistent(h, e_attributes, e_target):\n","\n","\n","\n","        covers = True\n","        for i in range(num_attributes):\n","            if h[i] != '?' and h[i] != e_attributes[i]:\n","                covers = False\n","                break\n","\n","        if e_target == 'Yes':\n","\n","            return covers\n","        else:\n","            return not covers\n","\n","\n","    def is_more_general(h1, h2):\n","\n","\n","\n","        if len(h1) != len(h2):\n","\n","            return False\n","\n","        h1_more_general = False\n","        for i in range(num_attributes):\n","            if h1[i] == '?' and h2[i] != '?':\n","                h1_more_general = True\n","            elif h1[i] != '?' and h1[i] != h2[i]:\n","                return False\n","\n","\n","        return h1_more_general\n","\n","\n","    for example in data_rows:\n","        if not example or len(example) != num_attributes + 1:\n","             continue\n","\n","        e_attributes = example[:-1]\n","        e_target = example[-1]\n","\n","\n","        if not S:\n","             return \"Error: Specific boundary became empty (inconsistent data).\", G, S\n","        if not G:\n","             return \"Error: General boundary became empty (inconsistent data).\", G, S\n","\n","\n","        if e_target == 'Yes':\n","\n","            G = [g for g in G if is_consistent(g, e_attributes, e_target)]\n","\n","\n","            new_S = []\n","            for s in S:\n","                if not is_consistent(s, e_attributes, e_target):\n","\n","\n","                    generalized_s = list(s)\n","                    for i in range(num_attributes):\n","                        if generalized_s[i] != e_attributes[i]:\n","                            generalized_s[i] = '?'\n","\n","\n","                    new_S.append(generalized_s)\n","                else:\n","\n","                    new_S.append(s)\n","\n","            S = new_S\n","\n","\n","            minimal_S = []\n","            for h1 in S:\n","                is_minimal = True\n","                for h2 in S:\n","\n","                    if h1 != h2 and is_more_general(h2, h1):\n","                        is_minimal = False\n","                        break\n","                if is_minimal:\n","                    minimal_S.append(h1)\n","            S = minimal_S\n","\n","\n","        elif e_target == 'No':\n","\n","            S = [s for s in S if is_consistent(s, e_attributes, e_target)]\n","\n","\n","            new_G = []\n","            for g in G:\n","                if not is_consistent(g, e_attributes, e_target):\n","\n","\n","                    minimal_specializations = []\n","                    for i in range(num_attributes):\n","                        if g[i] == '?' and g[i] != e_attributes[i]:\n","\n","                            specialization = list(g)\n","                            specialization[i] = e_attributes[i]\n","\n","\n","                            is_consistent_with_S = True\n","                            for s in S:\n","                                if not is_consistent(specialization, s, 'Yes'):\n","                                     is_consistent_with_S = False\n","                                     break\n","                            if is_consistent_with_S:\n","                                minimal_specializations.append(specialization)\n","\n","\n","                    new_G.extend(minimal_specializations)\n","                else:\n","\n","                    new_G.append(g)\n","\n","\n","            maximal_G = []\n","            for h1 in new_G:\n","                is_maximal = True\n","                for h2 in new_G:\n","\n","                     if h1 != h2 and is_more_general(h2, h1):\n","                         is_maximal = False\n","                         break\n","                if is_maximal:\n","                     maximal_G.append(h1)\n","\n","            G = maximal_G\n","\n","\n","\n","    return \"Success\", G, S\n","\n","\n","\n","if isinstance(training_data, list) and training_data and isinstance(training_data[0], list):\n","    status, final_G, final_S = candidate_elimination_manual(training_data)\n","    print(\"\\nCandidate-Elimination Result:\")\n","    print(f\"Status: {status}\")\n","    print(\"Final General Boundary (G):\", final_G)\n","    print(\"Final Specific Boundary (S):\", final_S)\n","else:\n","    print(\"\\nCould not run Candidate-Elimination: Training data was not loaded correctly or is empty.\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Candidate-Elimination Result:\n","Status: Success\n","Final General Boundary (G): [['?', '?', '?', 'Strong', '?', '?']]\n","Final Specific Boundary (S): [['Sunny', 'Warm', '?', 'Strong', '?', '?']]\n"]}]},{"cell_type":"markdown","metadata":{"id":"671878f1"},"source":["## Demonstrate implementations\n","\n","Demonstrate implementations: Provide examples and demonstrations for each implemented algorithm and technique.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fb61e3ae","executionInfo":{"status":"ok","timestamp":1754296374496,"user_tz":-330,"elapsed":27,"user":{"displayName":"Strange -CEG","userId":"00171070495488945838"}},"outputId":"b9bfbb88-eedc-4107-f673-69796cf9df37"},"source":["print(\"--- Demonstrating Binning Algorithms ---\")\n","\n","print(\"Demonstrating: simple_binning(data, bins)\")\n","\n","\n","sample_data_binning = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 15, 85]\n","num_bins_input = 5\n","edges_bins_input = [0, 25, 50, 75, 100, 120]\n","\n","\n","binned_result_num = simple_binning(sample_data_binning, num_bins_input)\n","binned_result_edges = simple_binning(sample_data_binning, edges_bins_input)\n","\n","\n","print(\"\\nSample Input Data:\", sample_data_binning)\n","print(\"Binning with number of bins =\", num_bins_input)\n","print(\"Output (Bin Indices):\", binned_result_num)\n","print(\"Explanation: Each number in the output list is the index of the bin (starting from 0) that the corresponding value from the input data was assigned to when divided into\", num_bins_input, \"equal-width bins.\")\n","\n","print(\"\\nSample Input Data:\", sample_data_binning)\n","print(\"Binning with bin edges =\", edges_bins_input)\n","print(\"Output (Bin Indices):\", binned_result_edges)\n","print(\"Explanation: Each number in the output list is the index of the bin corresponding to the provided edges that the value from the input data falls into.\")\n","print(\"-\" * 40)\n","\n","\n","\n","print(\"\\n--- Demonstrating Min-Max Normalization ---\")\n","\n","print(\"Demonstrating: min_max_normalize(data)\")\n","\n","\n","sample_data_normalize = [15, 25, 35, 45, 55, 10, 60]\n","\n","\n","normalized_result = min_max_normalize(sample_data_normalize)\n","\n","\n","print(\"\\nSample Input Data:\", sample_data_normalize)\n","print(\"Output (Normalized Data):\", normalized_result)\n","print(\"Explanation: Each value in the input data has been scaled to a range between 0 and 1, where the minimum value in the original data becomes 0 and the maximum value becomes 1.\")\n","print(\"-\" * 40)\n","\n","\n","\n","print(\"\\n--- Demonstrating Hypothesis Testing ---\")\n","\n","print(\"Demonstrating: simple_hypothesis_test(group1_data, group2_data)\")\n","\n","\n","sample_group1 = [22, 25, 28, 24, 26]\n","sample_group2 = [18, 20, 21, 19, 23]\n","\n","\n","hypothesis_test_result = simple_hypothesis_test(sample_group1, sample_group2)\n","\n","\n","print(\"\\nSample Group 1 Data:\", sample_group1)\n","print(\"Sample Group 2 Data:\", sample_group2)\n","print(\"Output (Conclusion):\", hypothesis_test_result)\n","print(\"Explanation: This output indicates whether there is a statistically significant difference between the means of the two sample groups based on a simplified t-test, compared against a hardcoded critical value (approximation).\")\n","print(\"-\" * 40)\n","\n","\n","\n","print(\"\\n--- Demonstrating Chi-Square Test ---\")\n","\n","print(\"Demonstrating: simple_chi_square_test(observed_table)\")\n","\n","\n","sample_observed_table = [[10, 20], [30, 40]]\n","\n","chi_square_conclusion, chi_square_stat, chi_square_df = simple_chi_square_test(sample_observed_table)\n","\n","\n","print(\"\\nSample Observed Table:\")\n","\n","for row in sample_observed_table:\n","    print(row)\n","print(\"Output (Conclusion):\", chi_square_conclusion)\n","print(\"Output (Chi-Square Statistic):\", chi_square_stat)\n","print(\"Output (Degrees of Freedom):\", chi_square_df)\n","\n","\n","explanation = \"Explanation: The Chi-Square statistic measures the difference between the observed frequencies in the table and the frequencies that would be expected if there were no association between the categories. The conclusion is based on comparing this statistic to a critical value for the calculated degrees of freedom (using a hardcoded approximation).\"\n","if chi_square_df in {1: 3.84, 2: 5.99, 3: 7.81, 4: 9.49, 5: 11.07}:\n","    critical_val = {1: 3.84, 2: 5.99, 3: 7.81, 4: 9.49, 5: 11.07}[chi_square_df]\n","    explanation += f\" For df={chi_square_df} and alpha=0.05, the approximate critical value is {critical_val}.\"\n","else:\n","     explanation += \" A critical value for this degree of freedom was not available in the hardcoded table.\"\n","print(explanation)\n","print(\"-\" * 40)\n","\n","\n","\n","print(\"\\n--- Demonstrating Confusion Matrix ---\")\n","\n","print(\"Demonstrating: simple_confusion_matrix(actual_labels, predicted_labels)\")\n","\n","\n","sample_actual_labels = [0, 1, 0, 1, 0, 0, 1, 1, 0, 1]\n","sample_predicted_labels = [0, 1, 1, 1, 0, 1, 0, 1, 0, 0]\n","\n","\n","confusion_matrix_result = simple_confusion_matrix(sample_actual_labels, sample_predicted_labels)\n","\n","\n","print(\"\\nSample Actual Labels:\", sample_actual_labels)\n","print(\"Sample Predicted Labels:\", sample_predicted_labels)\n","print(\"Output (Confusion Matrix):\")\n","\n","if isinstance(confusion_matrix_result, list) and len(confusion_matrix_result) == 2 and len(confusion_matrix_result[0]) == 2:\n","    print(\"               Predicted 0   Predicted 1\")\n","    print(\"Actual 0:      \", confusion_matrix_result[0][0], \"         \", confusion_matrix_result[0][1])\n","    print(\"Actual 1:      \", confusion_matrix_result[1][0], \"         \", confusion_matrix_result[1][1])\n","else:\n","    print(confusion_matrix_result)\n","\n","print(\"Explanation: The confusion matrix summarizes the performance of a classification model. The cells represent: Top-Left (True Negatives), Top-Right (False Positives), Bottom-Left (False Negatives), Bottom-Right (True Positives).\")\n","print(\"-\" * 40)\n","\n","\n","\n","print(\"\\n--- Demonstrating Principal Component Analysis (PCA) ---\")\n","\n","print(\"Demonstrating: Mean calculation, Data Centering, Covariance Matrix calculation, and Data Projection (using approximated components) on Iris data.\")\n","\n","\n","print(\"\\nUsing Iris dataset (numerical features) as Sample Input Data.\")\n","print(\"First 5 rows of Iris Data:\")\n","for i in range(min(5, len(iris_data))):\n","    print(iris_data[i])\n","\n","\n","print(\"\\nIntermediate Results (from PCA implementation steps):\")\n","print(\"Feature Means:\", feature_means)\n","print(\"\\nFirst 5 Centered Data Samples:\")\n","for i in range(min(5, len(centered_data))):\n","    print(centered_data[i])\n","print(\"\\nCovariance Matrix:\")\n","if isinstance(covariance_matrix, list):\n","    for row in covariance_matrix:\n","        print([f\"{x:.4f}\" for x in row])\n","else:\n","    print(covariance_matrix)\n","\n","print(f\"\\nFirst 5 PCA-Transformed Data Samples (using k={k} approximated principal components):\")\n","for i in range(min(5, len(pca_transformed_data))):\n","    print([f\"{x:.4f}\" for x in pca_transformed_data[i]])\n","\n","print(\"Explanation: PCA involves centering the data, calculating the covariance matrix, determining principal components (eigenvectors), and projecting the data onto the space defined by the top components. The output shows the original data, intermediate results, and the final data projected onto a lower-dimensional space (using approximated components due to constraint).\")\n","print(\"-\" * 40)\n","\n","\n","\n","print(\"\\n--- Demonstrating FIND-S Algorithm ---\")\n","\n","print(\"Demonstrating: find_s_manual(training_data)\")\n","\n","\n","print(\"\\nUsing EnjoySport training data (read manually from CSV) as Sample Input Data.\")\n","print(\"Training Data:\")\n","if isinstance(training_data, list):\n","    for row in training_data:\n","        print(row)\n","else:\n","    print(training_data)\n","\n","\n","\n","if isinstance(training_data, list) and training_data and isinstance(training_data[0], list):\n","    find_s_hypothesis = find_s_manual(training_data)\n","else:\n","    find_s_hypothesis = \"Could not run FIND-S: Training data was not loaded correctly.\"\n","\n","\n","print(\"\\nOutput (Final Most Specific Hypothesis):\", find_s_hypothesis)\n","print(\"Explanation: The FIND-S algorithm finds the most specific hypothesis that is consistent with all positive training examples. It ignores negative examples. The output is a hypothesis represented as a list of attribute values or wildcards ('?').\")\n","print(\"-\" * 40)\n","\n","\n","\n","print(\"\\n--- Demonstrating Candidate-Elimination Algorithm ---\")\n","\n","print(\"Demonstrating: candidate_elimination_manual(training_data)\")\n","\n","\n","print(\"\\nUsing EnjoySport training data (read manually from CSV) as Sample Input Data.\")\n","print(\"Training Data:\")\n","if isinstance(training_data, list):\n","    for row in training_data:\n","        print(row)\n","else:\n","    print(training_data)\n","\n","\n","\n","if isinstance(training_data, list) and training_data and isinstance(training_data[0], list):\n","    ce_status, ce_final_G, ce_final_S = candidate_elimination_manual(training_data)\n","else:\n","    ce_status = \"Could not run Candidate-Elimination: Training data was not loaded correctly.\"\n","    ce_final_G = []\n","    ce_final_S = []\n","\n","print(\"\\nOutput (Candidate-Elimination Result):\")\n","print(f\"Status: {ce_status}\")\n","print(\"Final General Boundary (G):\", ce_final_G)\n","print(\"Final Specific Boundary (S):\", ce_final_S)\n","print(\"Explanation: The Candidate-Elimination algorithm maintains a version space defined by a General (G) boundary and a Specific (S) boundary. G contains the most general hypotheses consistent with the data, and S contains the most specific. The output shows the final boundaries after processing the training examples, representing the set of all hypotheses consistent with the data.\")\n","print(\"-\" * 40)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--- Demonstrating Binning Algorithms ---\n","Demonstrating: simple_binning(data, bins)\n","\n","Sample Input Data: [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 15, 85]\n","Binning with number of bins = 5\n","Output (Bin Indices): [0, 0, 1, 1, 2, 2, 3, 3, 4, 4, 0, 4]\n","Explanation: Each number in the output list is the index of the bin (starting from 0) that the corresponding value from the input data was assigned to when divided into 5 equal-width bins.\n","\n","Sample Input Data: [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 15, 85]\n","Binning with bin edges = [0, 25, 50, 75, 100, 120]\n","Output (Bin Indices): [0, 0, 1, 1, 2, 2, 2, 3, 3, 4, 0, 3]\n","Explanation: Each number in the output list is the index of the bin corresponding to the provided edges that the value from the input data falls into.\n","----------------------------------------\n","\n","--- Demonstrating Min-Max Normalization ---\n","Demonstrating: min_max_normalize(data)\n","\n","Sample Input Data: [15, 25, 35, 45, 55, 10, 60]\n","Output (Normalized Data): [0.1, 0.3, 0.5, 0.7, 0.9, 0.0, 1.0]\n","Explanation: Each value in the input data has been scaled to a range between 0 and 1, where the minimum value in the original data becomes 0 and the maximum value becomes 1.\n","----------------------------------------\n","\n","--- Demonstrating Hypothesis Testing ---\n","Demonstrating: simple_hypothesis_test(group1_data, group2_data)\n","\n","Sample Group 1 Data: [22, 25, 28, 24, 26]\n","Sample Group 2 Data: [18, 20, 21, 19, 23]\n","Output (Conclusion): Reject Null Hypothesis (significant difference detected)\n","Explanation: This output indicates whether there is a statistically significant difference between the means of the two sample groups based on a simplified t-test, compared against a hardcoded critical value (approximation).\n","----------------------------------------\n","\n","--- Demonstrating Chi-Square Test ---\n","Demonstrating: simple_chi_square_test(observed_table)\n","\n","Sample Observed Table:\n","[10, 20]\n","[30, 40]\n","Output (Conclusion): Fail to Reject Null Hypothesis (No significant association detected)\n","Output (Chi-Square Statistic): 0.7936507936507936\n","Output (Degrees of Freedom): 1\n","Explanation: The Chi-Square statistic measures the difference between the observed frequencies in the table and the frequencies that would be expected if there were no association between the categories. The conclusion is based on comparing this statistic to a critical value for the calculated degrees of freedom (using a hardcoded approximation). For df=1 and alpha=0.05, the approximate critical value is 3.84.\n","----------------------------------------\n","\n","--- Demonstrating Confusion Matrix ---\n","Demonstrating: simple_confusion_matrix(actual_labels, predicted_labels)\n","\n","Sample Actual Labels: [0, 1, 0, 1, 0, 0, 1, 1, 0, 1]\n","Sample Predicted Labels: [0, 1, 1, 1, 0, 1, 0, 1, 0, 0]\n","Output (Confusion Matrix):\n","               Predicted 0   Predicted 1\n","Actual 0:       3           2\n","Actual 1:       2           3\n","Explanation: The confusion matrix summarizes the performance of a classification model. The cells represent: Top-Left (True Negatives), Top-Right (False Positives), Bottom-Left (False Negatives), Bottom-Right (True Positives).\n","----------------------------------------\n","\n","--- Demonstrating Principal Component Analysis (PCA) ---\n","Demonstrating: Mean calculation, Data Centering, Covariance Matrix calculation, and Data Projection (using approximated components) on Iris data.\n","\n","Using Iris dataset (numerical features) as Sample Input Data.\n","First 5 rows of Iris Data:\n","[5.1, 3.5, 1.4, 0.2]\n","[4.9, 3.0, 1.4, 0.2]\n","[4.7, 3.2, 1.3, 0.2]\n","[4.6, 3.1, 1.5, 0.2]\n","[5.0, 3.6, 1.4, 0.2]\n","\n","Intermediate Results (from PCA implementation steps):\n","Feature Means: [5.843333333333335, 3.057333333333334, 3.7580000000000027, 1.199333333333334]\n","\n","First 5 Centered Data Samples:\n","[-0.743333333333335, 0.4426666666666659, -2.3580000000000028, -0.9993333333333341]\n","[-0.9433333333333342, -0.057333333333334124, -2.3580000000000028, -0.9993333333333341]\n","[-1.1433333333333344, 0.14266666666666605, -2.458000000000003, -0.9993333333333341]\n","[-1.243333333333335, 0.042666666666665964, -2.2580000000000027, -0.9993333333333341]\n","[-0.8433333333333346, 0.542666666666666, -2.3580000000000028, -0.9993333333333341]\n","\n","Covariance Matrix:\n","['0.6857', '-0.0424', '1.2743', '0.5163']\n","['-0.0424', '0.1900', '-0.3297', '-0.1216']\n","['1.2743', '-0.3297', '3.1163', '1.2956']\n","['0.5163', '-0.1216', '1.2956', '0.5810']\n","\n","First 5 PCA-Transformed Data Samples (using k=2 approximated principal components):\n","['-1.5300', '1.5868']\n","['-1.1770', '1.3638']\n","['-1.4557', '1.3269']\n","['-1.3342', '1.1274']\n","['-1.6512', '1.5395']\n","Explanation: PCA involves centering the data, calculating the covariance matrix, determining principal components (eigenvectors), and projecting the data onto the space defined by the top components. The output shows the original data, intermediate results, and the final data projected onto a lower-dimensional space (using approximated components due to constraint).\n","----------------------------------------\n","\n","--- Demonstrating FIND-S Algorithm ---\n","Demonstrating: find_s_manual(training_data)\n","\n","Using EnjoySport training data (read manually from CSV) as Sample Input Data.\n","Training Data:\n","['Outlook', 'Temperature', 'Humidity', 'Wind', 'Water', 'Forecast', 'EnjoySport']\n","['Sunny', 'Warm', 'Normal', 'Strong', 'Warm', 'Same', 'Yes']\n","['Sunny', 'Warm', 'High', 'Strong', 'Warm', 'Same', 'Yes']\n","['Rainy', 'Cold', 'High', 'Strong', 'Warm', 'Change', 'No']\n","['Sunny', 'Warm', 'High', 'Strong', 'Cool', 'Change', 'Yes']\n","\n","Output (Final Most Specific Hypothesis): ['Sunny', 'Warm', '?', 'Strong', '?', '?']\n","Explanation: The FIND-S algorithm finds the most specific hypothesis that is consistent with all positive training examples. It ignores negative examples. The output is a hypothesis represented as a list of attribute values or wildcards ('?').\n","----------------------------------------\n","\n","--- Demonstrating Candidate-Elimination Algorithm ---\n","Demonstrating: candidate_elimination_manual(training_data)\n","\n","Using EnjoySport training data (read manually from CSV) as Sample Input Data.\n","Training Data:\n","['Outlook', 'Temperature', 'Humidity', 'Wind', 'Water', 'Forecast', 'EnjoySport']\n","['Sunny', 'Warm', 'Normal', 'Strong', 'Warm', 'Same', 'Yes']\n","['Sunny', 'Warm', 'High', 'Strong', 'Warm', 'Same', 'Yes']\n","['Rainy', 'Cold', 'High', 'Strong', 'Warm', 'Change', 'No']\n","['Sunny', 'Warm', 'High', 'Strong', 'Cool', 'Change', 'Yes']\n","\n","Output (Candidate-Elimination Result):\n","Status: Success\n","Final General Boundary (G): [['?', '?', '?', 'Strong', '?', '?']]\n","Final Specific Boundary (S): [['Sunny', 'Warm', '?', 'Strong', '?', '?']]\n","Explanation: The Candidate-Elimination algorithm maintains a version space defined by a General (G) boundary and a Specific (S) boundary. G contains the most general hypotheses consistent with the data, and S contains the most specific. The output shows the final boundaries after processing the training examples, representing the set of all hypotheses consistent with the data.\n","----------------------------------------\n"]}]},{"cell_type":"code","source":["\n","contacts = [\"ehcv\", \"fibo\", \"dgat\"]\n","\n","def function (num , co):\n","    dict = {\"2\" : [\"a\" , \"b\" , \"c\"] , \"3\" : [\"d\" , \"e\" , \"f\"], \"4\" : [\"g\" , \"h\" , \"i\"],\"5\" : [\"j\" , \"k\" , \"l\"] , \"6\" : [\"m\" , \"n\" , \"o\"], \"7\" : [\"p\" , \"q\" , \"r\" , \"s\"] , \"8\" : [\"t\" , \"u\" , \"v\"] , \"9\" : [\"w\" , \"x\" , \"y\" , \"z\"] }\n","    n = len(num)\n","    count = 0\n","    for c in co:\n","      if len(c) == n :\n","        match = True\n","        for i in range(n):\n","          if c[i] not in dict[num[i]]:\n","            match = False\n","            break\n","        if match == True:\n","          count += 1\n","    return count\n","print(function(\"3428\" , contacts))\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H1KW7-P3O1Q1","executionInfo":{"status":"ok","timestamp":1754298260444,"user_tz":-330,"elapsed":26,"user":{"displayName":"Strange -CEG","userId":"00171070495488945838"}},"outputId":"36ad0f5c-e458-4357-dd23-3cd42dd4c82e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2\n"]}]}]}